Assuming unrestricted shared filesystem usage.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 48
Rules claiming more threads will be scaled down.
Job stats:
job           count
----------  -------
all               1
phylo_tree        1
total             2

Select jobs to execute...
Execute 1 jobs...

[Thu Mar 13 08:48:45 2025]
localrule phylo_tree:
    input: results/CmdTAC_genomes_with_system.parquet, /home/gridsan/cdoering/LaubLab_shared/assembly_summary.txt
    output: results/CmdTAC_tree.newick, results/CmdTAC_tree.svg
    jobid: 1
    reason: Missing output files: results/CmdTAC_tree.svg
    wildcards: SYSNAME=CmdTAC
    resources: tmpdir=/state/partition1/slurm_tmp/20552.4294967291.0

[Thu Mar 13 08:50:00 2025]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...
Execute 1 jobs...

[Thu Mar 13 08:50:00 2025]
localrule all:
    input: results/CmdTAC_tree.svg
    jobid: 0
    reason: Input files updated by another job: results/CmdTAC_tree.svg
    resources: tmpdir=/state/partition1/slurm_tmp/20552.4294967291.0

[Thu Mar 13 08:50:00 2025]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2025-03-13T084842.539614.snakemake.log
